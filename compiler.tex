%!TEX root = paper.tex
\chapter{Type checking}
\label{sec:compiler}

We now give a formal model for how our implementation typechecks
\unit{}s which still have unfilled requirements.

%   It's not possible to
%   give a full semantics, since that would involve formalizing all of
%   Haskell as implemented by GHC, but we will informally explain the
%   operation of the judgments we assume are given to us.

\section{Semantic objects}
\label{sec:semantic-objects}

\begin{figure}
\[ \DIGinterface{} \]
\caption{Semantic objects of GHC Haskell with \Backpack{}}
\label{fig:semantic-objects}
\end{figure}

The semantic objects of GHC Haskell, extended with \Backpack{}, are
given in Figure~\ref{fig:semantic-objects}.  These semantic objects
correspond closely to the top-level declarations supported by
Haskell's syntax, but with a few key differences: first, every
identifier is resolved to an \emph{original name} ($N$) which identifies
the exact module that holds the declaration describing this identifier;
second, all declarations are explicitly annotated with types ($\tau$), kinds ($\kappa$) and
roles ($\rho$).\footnote{Type families are not annotated with roles, because their
type parameters are always at nominal role.}  If the kinds or roles are not
relevant to a judgment, we may elide them.

The most important semantic object is the module type ($T$).  A module
type consists of four components:

\begin{enumerate}

    \item The export list ($\UNs ::= \overline{N}$), which
    specifies what entities are brought into scope when a module is
    imported.  Every original name in an export list has a unique
    occurrence name (e.g., $\UNs(n) = N$).

    \item The type declarations ($\Utys$), which give
    definitions for each entity provided by a module.  Every defined
    entity list defines a particular entity $n$ (shaded in gray
    in Figure~\ref{fig:semantic-objects}).  Like export lists,
    each declaration in a module has a unique occurrence name
    (e.g., $\Utys(n) = \Uty$).

    \item A set of instances ($\Uinsts$), which specifies the class
    and family instances defined in this module.

    \item The set of modules transitively imported by this module
    ($\Uimps$), which controls the set of \emph{orphan instances}
    (instances which may not necessarily be in scope) which are in scope
    when performing type class resolution.  If the module in question
    defines orphan instances, its identity is included in this list.

\end{enumerate}
%
Below is a simple example of a module's Haskell source code and its
corresponding module type:

\vspace{-1em}
\begin{figure}[H]
\centering
\begin{shortmath}
\begin{tabular}{p{0.30\textwidth} p{0.30\textwidth}}
\begin{lstlisting}
module A where
    data T = MkT
    f = MkT
    instance Eq T where
        MkT == MkT = True
\end{lstlisting}
&
\vspace{-12pt}
\[
\begin{array}{l}
    \UobjIface\: (\Mod{P_0}{A}.\texttt{T}, \Mod{P_0}{A}.\texttt{f}) \\
    \qquad\texttt{data T where MkT} :: \Mod{P_0}{A}.\texttt{T} \\
    \qquad\texttt{f} :: \Mod{P_0}{A}.\texttt{T} \\
    \qquad\texttt{instance} :: N_{Eq}~\Mod{P_0}{A}.\texttt{T} \\
\end{array}
\]
\end{tabular}
\end{shortmath}
\end{figure}

\vspace{-2em}
\noindent
Here, $P_0$ represents the unit identifier that this module was
being typechecked as a part of (for example, if \verb|module A| was
in the component \verb|p| with no holes, then $P_0 = \uidl{p}{}$),
and $N_\texttt{Eq}$ is the original name of the equality type
class (not shown, but part of Haskell's Prelude, a set of declarations
which are always in scope.)

There are some slight differences with the module type of a signature:

\vspace{-1em}
\begin{figure}[H]
\centering
\begin{shortmath}
\begin{tabular}{p{0.30\textwidth} p{0.30\textwidth}}
\begin{lstlisting}
signature A where
    data T
    f :: T
\end{lstlisting}
&
\[
\begin{array}{l}
    \UobjIface\: (\nhv{A.T}, \nhv{A.f}) \\
    \qquad\texttt{data T} \\
    \qquad\texttt{f} :: \nhv{A.T}
\end{array}
\]
\end{tabular}
\end{shortmath}
\end{figure}

\vspace{-2em}
\noindent
Instead of original names based off of the ambient unit identifier $P_0$,
every defined entity is allocated a fresh name hole (e.g., $\nhv{A.T}$),
which may be subsequently substituted with the actual original name of the
implementing declaration.

A collection of module types forms a component ($\Xi$), where each module
type is annotated with a $+$ or $-$ to indicate if it is a module or
signature.   Although the syntax of component types suggests that a module
type can be put into the context at any name, a particular module
identity is baked into the module type (as can seen in the example
above); a module type must be placed in the context consistently with
the module identifier it was typechecked with.  (We could have avoided
this by applying a ``selfification'' step prior to adding
modules to the context, but the current presentation is more direct and
accurately describes how GHC is implemented.)

\section{Typing rules}

We organize our formalization of \Backpack{} typing into a few
concerns:

\begin{itemize}
    \item The assumed Haskell judgments (Figure~\ref{typing:haskell}) are the
        Haskell type-checking judgments we assume are available, but which
        we do not formalize.

    \item The top-level typing rules (Figure~\ref{typing:main}) tell us
        how to typecheck the declarations of a component and form the final
        component type.

    \item The type lookup and renaming rules (Figure~\ref{typing:lookup}) tell us how to
        get the type of a module by looking up the original type from
        the context, and then \emph{renaming} it according to the substitution
        recorded in the module identifier.  We will explain the difference
        between type lookup and signature type lookup in more detail later.

    \item The merging rules (Figure~\ref{typing:merging}) specify how the
        module types are merged together during signature merging.

    \item The subtyping rules (Figures~\ref{typing:top-subtyping}--\ref{typing:subtyping})
        specify when one module type is a subtype of another, and is used
        by both signature merging and dependency matching.

\end{itemize}
Most typing rules require the following three pieces of context:

\begin{itemize}
    \item The external component type context $\Gamma ::= \overline{p : \Xi}$,
        which records the types of all components we have previously
        typechecked.  These components are typed but not instantiated.
    \item The local type context $\Delta :: \overline{m : T^s}$,
        which records the types of the modules and signatures we have typechecked
        from the current package.
    \item The current unit identifier $P_0$, which identifies the component
        we are typechecking. It is used to generate the original names
        of declarations in modules and determine when a lookup should be
        done in the local type environment.
\end{itemize}
Some rules require some extra context:

\begin{itemize}
    \item The logical context $\mathcal{L} ::= \overline{m \mapsto M}$ specifies
        which module identity is brought into scope when a module name is imported.
        It is needed when typechecking unrenamed Haskell source code, but is
        otherwise not needed for typechecking.

    \item The shape context $\shctx ::= \overline{p : \lctx}$ specifies what
        module identities are provided by a package; this is used to resolve
        a list of \texttt{dependency} declarations into the logical context $\mathcal{L}$.
\end{itemize}

\subsection{Assumed Haskell judgments}

\input{typing/haskell}

We assume some fairly conventional judgments for various operations on
Haskell, which we do not formalize:

\begin{itemize}
    \item Module and signature typechecking are judgments which typecheck
    module (\I{hsmod}) and signature (\I{hssig}) source into module
    types.  Alongside the usual context, these judgments also require
    the logical context $\mathcal{L}$ so that they can resolve imports,
    and the name $m$ of the module they are typechecking (along with $P_0$,
    this will determine what original names of the declarations in
    the module and signatures will be: $\Mod{P_0}{m}.n$ in the case
    of a module, and $\nhv{m.n}$ in the case of a signature.)

    \item We also need judgments for testing type and kind equality.
    These require a context, because type synonyms and type families
    can introduce nontrivial definitional equalities between types that
    are syntactically dissimilar.

    \item Finally, we need a judgment for testing if a type class
    instance is derivable from the instances available in the context,
    plus some set of orphan instances (indicated by \I{orphs}).  Informally,
    this judgment collects all instances which are transitively reachable
    from \I{orphs}, as well as the modules which define all of the types
    mentioned in \I{inst}, and then runs the instance constraint solver
    to see if \I{inst} is implied by these instances.
\end{itemize}

\subsection{Top-level typing rules}

\input{typing/main}

Broadly speaking, the process of typechecking a component involves
bringing all of the modules from its dependencies into scope
($\mathcal{L} ::= \overline{m \mapsto M}$), and then type checking each
module and signature in this context.  \textsc{TComp} computes the set
of in-scope modules by looking up the provided modules from the
component shape context (\textsf{exposes}).  As we typecheck each module
(\textsc{TModule}) and signature (\textsc{TSignature}), \textsc{TSeq}
adds their module types to the home module context ($\Delta ::=
\overline{m : T^s}$), so that their types are available for subsequent
modules and signatures.

The most complicated rule is the rule for typechecking signatures
(\textsc{TSignature}).  Like \textsc{TModule}, we first defer to an assumed
judgment to typecheck the source \I{hssig}.  However, after the module
type for the \emph{local} signature is computed, we must \emph{merge} it
with all of the inherited signatures (computed by \textsf{inherits} and
recorded in $\mathcal{D} ::= \overline{m \mapsto \overline{M}}$).

\subsection{Type lookup rules}
\label{sec:typing/lookup}

\input{typing/lookup}

During the course of typechecking a Haskell module, we will often have
to lookup the type of an original name.  In plain
Haskell, the type of each original name is recorded directly
in the context; in \Backpack{}, we may need to \emph{substitute} the
type declaration, substituting any name holes embedded within it.
\textsc{TUnit} contains the key rule: to determine the type of a module
$\Mod{p[S]}{m}$, lookup the type and apply its substitution.

Substitutions on semantic objects are not ordinary substitutions: not
only do we substitute all module identities (as in
\textsc{SName}), but we must also substitute over names
(\textsc{SNameHole}), according to the exports of the modules we are
substituting with: substitution requires us to recursively look up the
types of these modules.  Additionally, when we do substitutions on
\I{orphs}, to maintain transitivity, we must substitute in all of
the transitively imported orphans of the implementing module.

%   During the course of typechecking, ordinary type lookup will only ever
%   refer to signature types in $\Delta$; signature types of components are
%   used only during the process of signature merging, in order to form a
%   merged signature $m : T^- \in \Delta$, which incorporates the
%   requirements of all the (transitive) dependencies of the component.
%   In particular, if we are looking up the type of \nhv{m.n} (\textsc{TNameHole}),
%   this is done by looking up the type in the \emph{local} requirement
%   \hv{m}, not the requirement of the package where \nhv{m.n} came
%   from (indeed, the original name doesn't provide this information!)

Ordinarily, type lookup will only look up \emph{modules} (types
with polarity $+$) from the component environment.  However, when merging
signatures, we must also lookup signatures from the component environment
for merging.  In this case, there are two further possible cases which
must be handled: \textsc{SRnOrphan} and \textsc{SRnNameHole} (greyed in
the figure).  These rules handle the situation when the there is no
type for the target of the substitution in the local context $\Delta$.
In these cases, we just directly rename without consulting the context:
signature merging proper handles updating any name holes into their
final identities.  Orphans are handled similarly.

% Key points:
%   - Signatures process one-by-one, as an earlier signature
%     can cause a later one to merge.  Same with exports.
% Properties we want: (1) signature can import other signature, (2) signature sees the same view of an import A as other modules would, (3) semantics should be forwards compatible with a recursive semantics, (4) signature should be able to refine type so that merging that would otherwise fail succeeds
%   - Non-recursive case is easier because we don't have to preemptively
%     merge all types (running afowl of (4))
%   - Thinning doesn't work too well: want to thin BEFORE you typecheck
%   so that you avoid typechecking things you don't know.
%   - Thinning has a relationship with explicit signature exports


% TODO: Need to also update transitively reachable modules when this
% occurs

\subsection{Merging rules}

\input{typing/merging}

Merging occurs when we merge $n$ signatures together, forming a new
signature which is a subtype of all the original signatures (or failing
if no such signature exists).  The key rule is \textsc{MSigType}, which performs
the following operations:

\begin{itemize}
    \item First, we perform \emph{export matching}, computing the merged
    export list, where name holes are subsumed by reexported original
    names. (Line 1) The new export list induces a name substitution, which we apply
    to each of the signature types. (Line 2)

    \item Next, we merge all of the entities of the interface together,
    producing a candidate merged signature $T_M$ (Line 3); it is a candidate signature
    because during this step, we do \emph{not} check if the merged types match.

    \item Finally, we check that the merged type is a subtype of each of the
    (substituted) input signature types. (Line 4)
\end{itemize}

There are two subtleties in this procedure.  First, the declaration
merge is \emph{nondeterministic} (``pick an arbitrary one'').  This
nondeterminism is benign, as after merging we show that $\Uty_1
=_\textsf{hs} \Uty_2$ (via the subtyping check): the choice didn't
matter in the first place.

Second, because of the above nondeterminism, we must be a little careful
how we formulate the check for type synonym cycles.  Consider:

\vspace{-1em}
\begin{figure}[H]
\centering
\begin{shortmath}
\begin{tabular}{p{0.30\textwidth} p{0.30\textwidth}}
\begin{lstlisting}
signature A where
    data A
    type B = A
\end{lstlisting}
&
\begin{lstlisting}
signature A where
    type A = B
    type B = Int
\end{lstlisting}
\end{tabular}
\end{shortmath}
\end{figure}

\vspace{-2em}
\noindent
If we prefer the declarations from the second signature, there is no cycle;
but if we take \verb|type A = B| and \verb|type B = A|, there is a cycle.
The acyclicity check verifies that under \emph{all} possible merges, there
are no type synonym cycles.

\paragraph{Behavior with ill-typed signatures}  In our implementation,
we noticed that the typing rules we have
described above have some surprising behavior when typechecking signatures that
are not well-typed: we may temporarily end up with types in our context
that are ill-kinded, or generally nonsensical.  For example, we might
merge \verb|data T; f :: T| and \verb|data T a; f :: T a| to get
\verb|data T; f :: T a|, which is obviously ill-kinded.  It seems difficult
to avoid behavior like this in the presence of mutual recursion (both MixML
and \OldBackpack{} also exhibit this behavior); fortunately,
this does not affect soundness (eventually we notice that \verb|data T|
and \verb|T a| are incompatible and reject the merge).

\subsection{Subtyping rules}

\input{typing/subtyping}
\input{typing/kinding}

Last but not least, the subtyping judgment specifies when one module type
is a subtype of another.  The main judgment \textsc{SubMod} tests if
a module type is a subtype of another, under some context.  Both module
types are assumed to have had a name substitution applied to them, so that
subtyping on exports can be checked using a simple superset operation.

Unusually, when we check for subtyping of declarations, we add $T_M$
to the context.  To see why this is necessary, consider if we were
checking that \verb|type T = Int; f :: Int| was a subtype of \verb|data T; f :: T|.
When checking that \verb|f :: Int| is a subtype of \verb|f :: T|, we must lookup
the declaration of \verb|T| in the context: $m : T_M^-$ precisely provides
information that \verb|T| is a type synonym \verb|type T = Int|.  If
instead the lookup gave us the abstract definition of \verb|T|, we would conclude
that \verb|Int| and \verb|T| were not equal.  We similarly add $T_M$ to
the context when testing if instances are solvable.

Because every module type records all orphan modules that it transitively
imports, the most natural subtyping relation for orphans is, in fact, to
always assume any orphans brought into scope by the signature, no matter
whether or not the implementing module imported those orphan modules. Thus,
there is no $\Uimps' \supseteq \Uimps$ rule in the judgment; furthermore, when
considering instance solvability, we bring into scope both orphans from the
signature as well as the module.

\paragraph{Declaration subtyping and pre-subtyping}
In our presentation, declaration subtyping is organized in a subtyping
relation (\textsc{SubDecl}) and a pre-subtyping relation: the subtyping
relation tests if the kinds of the declarations are equal and the roles
are compatible, and then defers to the pre-subtyping relation for
case-by-case subtyping on each different type of declaration.  The
non-reflexive rules are boxed, and specify which declarations can
validly implement abstract data, classes and closed type families.

\paragraph{Subroling, subtyping and representational injectivity}
The condition on roles in \textsc{SubDecl} is quite interesting:
it states that if $\Uty'$ is \emph{representationally injective},
to show that $\Uty \le \Uty'$,
is sufficient to show that $\overline{\rho'_i \le \rho_i}$: i.e.,
the roles of the supertype are subroles of the subtype.
Subroling, whose definition we inherit from~\cite{Breitner:2014:SZC:2692915.2628141},
is oriented in the opposite direction of the subtyping relation.

To explain why the rule is setup this way, we first have to briefly
explain
the function of roles in Haskell.  In Haskell, there are two notions of
equality: nominal equality and representational equality.\footnote{There is also
a third notion, phantom equality, which is degenerate: all types are phantom
equal to all other types.}  Nominal
equality is the traditional notion of type equality, whereas
representational equality specifies when the underlying representation
of a type are equal.  Nominal equality implies representational
equality, but a \verb|newtype| can introduce a nominal distinction between
two types without changing the underlying representation. If I declare
\verb|newtype Age = Age Int|, I now have a representational equality
between \verb|Age| and \verb|Int| (written as $\texttt{Age}
\sim_\textsf{R} \texttt{Int}$), but no nominal equality (written as $\texttt{Age}
\not\sim_\textsf{N} \texttt{Int}$).

Roles are associated with the type parameters of type constructor and
are used in two ways:

\begin{enumerate}
    \item \emph{Application.} If we would like to show $\texttt{T}~\tau \sim_\textsf{R}
    \texttt{T}~\sigma$, we must show that $\tau \sim_\rho \sigma$, where
    $\rho$ is the \emph{role} of the parameter of the type constructor
    \verb|T|.  A data type like \verb|data T a = T a| will have its parameter
    at representational role, since you only require $\tau \sim_R
    \sigma$, while a data type that uses a type family to match on
    nominal identity of the type parameter will have nominal role,
    requiring us to show that $\tau \sim_N \sigma$.

    \item \emph{Decomposition.}  If we know that $\texttt{T}~\tau \sim_\textsf{R}
    \texttt{T}~\sigma$, we can infer that $\tau \sim_\rho \sigma$ (where $\rho$
    is the role of the parameter of the type constructor),
    but only if \verb|T| is \emph{representationally injective}.  Data types
    are representationally injective, but newtypes are not: if you
    have \verb|newtype T a = MkT Int|,
    we have $\texttt{T}~\tau \sim_\textsf{R} \texttt{Int}$ for any $\tau$,
    even if the type parameter of \verb|T| is declared
    to be nominal.  In this case,
    it would be unsound to assume that given
    $\texttt{T}~\tau \sim_\textsf{R} \texttt{T}~\sigma$, $\tau \sim_\textsf{N} \sigma$ holds!
\end{enumerate}
%
Roles follow a subroling relationship, which specifies that if you have
a data type which a type parameter with role $\rho$, it is valid to
replace the role with a role $\rho'$, where $\rho' \le \rho$; for example,
even though \verb|data T a = T a| is representational in its first
argument by default, we can explicitly override it to be nominal in its
first argument, since $\textsf{N} \le \textsf{R}$.  Do subroles induce
a supertyping relationship?  If we consider only \emph{applications}, it would
seem this should be the case:

\vspace{-1em}
\begin{figure}[H]
\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}
\begin{lstlisting}
signature A where
    type role T nominal
    data T a
\end{lstlisting}
&
\begin{lstlisting}
module A where
    type role T representational
    data T a = MkT a
\end{lstlisting}
\end{tabular}
\end{figure}
\vspace{-1em}
%
\noindent
Under the signature, given $\tau \sim_\textsf{N} \sigma$, we can infer
$\texttt{T}~\tau \sim_\textsf{R} \texttt{T}~\sigma$; however,
$\tau \sim_\textsf{R} \sigma$ would not be sufficient.
Under the module, both conditions are sufficient to infer
$\texttt{T}~\tau \sim_\textsf{R} \texttt{T}~\sigma$: thus,
more programs typecheck when a type argument is at representational role
than when is at a nominal role.

However, with decompositions, the opposite holds. Suppose that \verb|T|
were representationally injective: under the signature, given
$\texttt{T}~\tau \sim_\textsf{R} \texttt{T}~\sigma$, we could
show $\tau \sim_\textsf{N} \sigma$; we could \emph{not} infer
this under the module.
Fortunately, abstract data is \emph{not}
representationally injective (Figure~\ref{fig:representational-injectivity}), as it can be implemented via
a newtype (\textsc{SubNewtypeAbsData} in Figure~\ref{typing:subtyping}),
so this counterexample does not hold.

\paragraph{Subtyping synonyms}
The subtyping rules for type synonyms (\textsc{SubTypeAbsData} and
\textsc{SubTypeAbsClass}) are worth extra comment, because the implementing
type synonyms are required to be \emph{nullary}: for example, \verb|type M a = a|
is not a valid implementation of the abstract \verb|data M a|,
but \verb|type M = Maybe :: * -> *| is.  This restriction
stems from an old design decision in Haskell to not support \emph{type level
lambdas}.  This restriction greatly helps type inference, since given the
type equality $t~a = s~b$, we can now conclude that $t = s$ and $a = b$
(this property is called \emph{generativity}).  Thus, GHC restricts type
synonym applications to be fully saturated (unlike data declarations, which can
be partially applied); similarly, a type synonym can only be used in place
of a data declaration if this could not result in partially applied type
synonyms.

\section{Substitutability and type inference}
\label{sec:substitutability}

One property of the GHC's type system which is required for
the soundness of \Backpack{} is \emph{substitutability}: given that
a module type checks under some type environment, if we apply a
valid name substitution to the environment, the module must
continue to typecheck.

In the absence of type classes and type families (see
Section~\ref{sec:metatheory} for a detailed discussion on these
features), this property largely holds for Haskell's type system.
However, we found one subtle case related to GHC's treatment
of \emph{inaccessible code}.  Inaccessible code occurs when
GHC is able to prove that a constraint is unsatisfiable; for
example:

\begin{lstlisting}
    f :: (Int ~ Bool) => a -> b
    f x = x
\end{lstlisting}
%
Here, the constraint that \verb|Int| be nominally equal to \verb|Bool|
can never be fulfilled, so GHC accepts the otherwise ill-typed
function definition.  In $\mathrm{OutsideIn(X)}$~\cite{Vytiniotis:2011:OMT:2139531.2139533},
this behavior occurs when we apply the \textsc{faildec} constraint
solving rule, which states that
constraint solving should immediately fail if we attempt to unify
two distinct type constructors (i.e., two type constructors with
different original names), on a \emph{given
constraint}: constraint solving failure on a given constraint means that
the code behind the constraint is inaccessible.

Unfortunately, this rule is unsound in the presence of \Backpack{}:

\begin{lstlisting}
    signature A where
        data T
        data S
    module B where
        import A
        f :: (T ~ S) => a -> b
        f x = x
\end{lstlisting}

As \verb|T| and \verb|S|, at the point of typechecking \verb|B|, have
distinct original names, the constraint solver might conclude that
\verb|f|'s body is inaccessible.  But if we subsequently set
\verb|type S = T|, now \verb|T ~ S| does indeed hold!

Fortunately, as the $\mathrm{OutsideIn(X)}$ paper observes, it is sound
to \emph{not} eagerly fail when simplifying givens.  So the fix is simple:
don't eagerly fail if the constraint involves an abstract type.
Intuitively, abstract types in \Backpack{} behave more like \emph{skolem
variables}, in the sense that they don't unify with anything, but cannot
be assumed to be distinct from all types (the client will instantiate
the skolem variable to whatever they please.)

\iffalse%
\section{Role subtyping}

Though not formalized above, Haskell's type system also includes the
concept of \emph{roles}~\cite{Weirich:2011:GTA:1925844.1926411,Breitner:2014:SZC:2692915.2628141}.  The parameters of all type constructor are annotated with roles,
which mark the distinction of whether or not the type constructor
cares about the \emph{nominal} or \emph{representational} identity
of a type at that position.

\Red{Finish this after we decide it's good}
\fi

% Things that are missing
%   - Component sequencing OK
%   - Functorial rules for rename/renamesig OK
%   - Import subtyping / instantiation
%   - Info equality OK
%   - Acyclicity OK
%
% Should add labels

% Things to talk about:
%   - Temporary bogus types. MixML and Backpack have this problem
%     (Backpack in particular: if you define a type and refer to it,
%     but that type is already in context, which do you use.  Name
%     is consistent, but not necessarily definition!)
%   - Cyclic exports when you add signature reexports to recursive
%   Backpack
%   - Recursive design space is big. hs-boot for hsigs? Do signature
%   declarations become before or after dependencies?  Signature
%   should see anything, but also refine recursive occurences of self?
